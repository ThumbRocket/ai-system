{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhWwfK2rbxhl"
   },
   "source": [
    "# Getting Started: Install QPyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3452,
     "status": "ok",
     "timestamp": 1628520640291,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "kFvLKcLbPY1s",
    "outputId": "fe84d717-9966-414f-d8d2-9c8703d4c6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sphinx>=1.4 (from -r requirements.txt (line 1))\n",
      "  Downloading sphinx-8.0.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: ipykernel in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (6.29.5)\n",
      "Collecting nbsphinx (from -r requirements.txt (line 3))\n",
      "  Downloading nbsphinx-0.9.5-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting Ninja (from -r requirements.txt (line 4))\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: torchvision in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: tqdm in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
      "Collecting transformers==4.37.0 (from -r requirements.txt (line 8))\n",
      "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qtorch==0.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading qtorch-0.3.0-py3-none-any.whl.metadata (455 bytes)\n",
      "Requirement already satisfied: filelock in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (0.24.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.0->-r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (0.4.3)\n",
      "Requirement already satisfied: torch>=1.5.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from qtorch==0.3.0->-r requirements.txt (line 9)) (2.4.0)\n",
      "Collecting sphinxcontrib-applehelp (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sphinxcontrib-qthelp (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: Pygments>=2.17 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.18.0)\n",
      "Collecting docutils<0.22,>=0.20 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting snowballstemmer>=2.2 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting babel>=2.13 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting alabaster>=0.7.14 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx>=1.4->-r requirements.txt (line 1))\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tomli>=2 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (8.26.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (5.14.3)\n",
      "Collecting nbconvert!=5.4,>=5.3 (from nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat (from nbsphinx->-r requirements.txt (line 3))\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 5)) (9.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0->-r requirements.txt (line 8)) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0->-r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: decorator in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (3.0.47)\n",
      "Requirement already satisfied: stack-data in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from Jinja2>=3.1->sphinx>=1.4->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 2)) (4.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (4.12.3)\n",
      "Collecting bleach!=5.0.0 (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: defusedxml in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.7.1)\n",
      "Collecting jupyterlab-pygments (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->nbsphinx->-r requirements.txt (line 3))\n",
      "  Using cached fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from nbformat->nbsphinx->-r requirements.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (3.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from beautifulsoup4->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/devrok/.conda/envs/qpt/lib/python3.10/site-packages (from sympy->torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (1.3.0)\n",
      "Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading qtorch-0.3.0-py3-none-any.whl (21 kB)\n",
      "Downloading sphinx-8.0.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nbsphinx-0.9.5-py3-none-any.whl (31 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Downloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.4/257.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.1 has a non-standard dependency specifier torch>=1.8.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: webencodings, snowballstemmer, Ninja, fastjsonschema, tinycss2, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, pandocfilters, mistune, jupyterlab-pygments, imagesize, docutils, bleach, babel, alabaster, sphinx, tokenizers, qtorch, transformers, nbformat, nbclient, nbconvert, nbsphinx\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.43.4\n",
      "    Uninstalling transformers-4.43.4:\n",
      "      Successfully uninstalled transformers-4.43.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autoawq 0.2.6 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\n",
      "ratsnlp 1.0.53 requires transformers==4.28.1, but you have transformers 4.37.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Ninja-1.11.1.1 alabaster-1.0.0 babel-2.16.0 bleach-6.1.0 docutils-0.21.2 fastjsonschema-2.20.0 imagesize-1.4.1 jupyterlab-pygments-0.3.0 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 nbsphinx-0.9.5 pandocfilters-1.5.1 qtorch-0.3.0 snowballstemmer-2.2.0 sphinx-8.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 tinycss2-1.3.0 tokenizers-0.15.2 transformers-4.37.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXNTg39objEC"
   },
   "source": [
    "# Lab 1. Quantizer Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1628520643374,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "b3YXBtJdPnmV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from qtorch.quant import Quantizer, quantizer\n",
    "from qtorch import FloatingPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1628520643379,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "MeKTakK2vy_G",
    "outputId": "e63a1907-105f-4e5d-ba5f-ab855cf7b506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9896, 0.2558, 0.0652],\n",
      "        [0.2630, 0.6916, 0.1466],\n",
      "        [0.0170, 0.6570, 0.6628]])\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.rand([3,3])\n",
    "print(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1628520643381,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "EApY1jmgPnmY",
    "outputId": "66f59382-80b7-4257-be4b-86e1c0f8a263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 255.0000, -255.0000],\n",
      "        [   1.4000,    1.6000]])\n"
     ]
    }
   ],
   "source": [
    "constant_input = torch.tensor([[255., -255.],[1.4, 1.6]])\n",
    "print(constant_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1628520643382,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "jDdkM_DIPnmZ"
   },
   "outputs": [],
   "source": [
    "# Example: FP4 (E2M1) Quantization 0 ~ 15\n",
    "bit = FloatingPoint(exp=2, man=1) # 한개는 sign\n",
    "quant = quantizer(forward_number=bit, forward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Function.apply of <class 'qtorch.quant.quant_function.quantizer.<locals>.Rounding'>>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1628520643382,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "AhIfnjodPnmZ",
    "outputId": "477d257f-0182-4ac4-cb37-2a2fcc79dc62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.5000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "random_output = quant(random_input)\n",
    "print(random_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1628520643383,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "YQvwyONzPnma",
    "outputId": "527d8fc5-43f6-4d99-be21-7d3c4c10a444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.0000, -6.0000],\n",
      "        [ 1.5000,  1.5000]])\n"
     ]
    }
   ],
   "source": [
    "constant_output = quant(constant_input)\n",
    "print(constant_output) # -6 ~ 6 -> 양자화 후 -255, 255 범위 내 표현할 수 있는 최대값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFxoNyqQc3z7"
   },
   "source": [
    "# Lab 2. Reduced-Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1628520643383,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "G0yRBZ2PW4Ay"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from qtorch.quant import Quantizer, quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import FloatingPoint\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2721,
     "status": "ok",
     "timestamp": 1628520646083,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "XESR-_sAW4A1",
    "outputId": "54e9b20f-d2d1-4cf7-9755-b9d65afe2aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:23<00:00, 7396329.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "ds = torchvision.datasets.CIFAR10\n",
    "path = os.path.join(\"./data\", \"CIFAR10\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
    "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
    "loaders = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=128,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1628520646658,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "mI5Eqkp0W4A3"
   },
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "bit_8 = FloatingPoint(exp=5, man=2)\n",
    "bit_16 = FloatingPoint(exp=6, man=9)\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = quantizer(forward_number=bit_8,\n",
    "                        forward_rounding=\"nearest\")\n",
    "grad_quant = quantizer(forward_number=bit_8,\n",
    "                        forward_rounding=\"nearest\")\n",
    "momentum_quant = quantizer(forward_number=bit_16,\n",
    "                        forward_rounding=\"stochastic\")\n",
    "acc_quant = quantizer(forward_number=bit_16,\n",
    "                        forward_rounding=\"stochastic\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=bit_8, backward_number=bit_8,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628520646658,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "HOImoaAsW4A4"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "# 동일한 Qunt를 사용?\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, quant, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        ####### FIXME #######\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.quant(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.quant(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.quant(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.quant(out)\n",
    "        #####################\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "    \n",
    "class PreResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,quant, num_classes=10, depth=20):\n",
    "\n",
    "        super(PreResNet, self).__init__()\n",
    "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
    "        n = (depth - 2) // 6\n",
    "\n",
    "        block = BasicBlock\n",
    "\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.layer1 = self._make_layer(block, 16, n, quant)\n",
    "        self.layer2 = self._make_layer(block, 32, n, quant, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, n, quant, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        self.quant = quant()\n",
    "        IBM_half = FloatingPoint(exp=6, man=9)\n",
    "        self.quant_half = Quantizer(IBM_half, IBM_half, \"nearest\", \"nearest\")\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, quant, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "            )\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.inplanes, planes, quant , stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, quant))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant_half(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.quant(x) # Quantization\n",
    "\n",
    "        x = self.layer1(x)  # 32x32\n",
    "        x = self.layer2(x)  # 16x16\n",
    "        x = self.layer3(x)  # 8x8\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.quant(x) # Quantization\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.quant_half(x) # Quantization\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628520646658,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "14jRstmDW4A5"
   },
   "outputs": [],
   "source": [
    "model = PreResNet(act_error_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628520646659,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "X9AmXt_zW4A5"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' # change device to 'cuda' if you want to run this example on cuda\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628520646659,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "g-pH0RDHW4A5"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = OptimLP(optimizer,\n",
    "                    weight_quant=weight_quant,\n",
    "                    grad_quant=grad_quant,\n",
    "                    momentum_quant=momentum_quant,\n",
    "                    acc_quant=acc_quant,\n",
    "                    grad_scaling=1/1000 # do loss scaling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628520646659,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "p0VLSx1oW4A5"
   },
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
    "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    if phase==\"train\": model.train()\n",
    "    elif phase==\"eval\": model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "            if phase==\"train\":\n",
    "                loss = loss * 1000 # do loss scaling\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 83.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.308834511566162, 'accuracy': 10.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                        optimizer=optimizer, phase=\"eval\")\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Epoch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38564,
     "status": "ok",
     "timestamp": 1628520685218,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "vbgMAJtoW4A6",
    "outputId": "28499849-a11d-471c-c6d2-5a295534581c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 37.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0\n",
      "Train loss    : 1.6348645886611939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 1\n",
      "Train loss    : 1.141644220275879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 2\n",
      "Train loss    : 0.9543998905563355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                optimizer=optimizer, phase=\"train\")\n",
    "    print(f'=====> Epoch {epoch}')\n",
    "    print(f'Train loss    : {train_res[\"loss\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 122.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0747511833190917, 'accuracy': 64.05999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                        optimizer=optimizer, phase=\"eval\")\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_MP5qXQdK20"
   },
   "source": [
    "# Lab 3.1. Trans-Precision Inference on CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1628520687102,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "WrNdpm-WXr7n"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, quant, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.quant(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.quant(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.quant(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.quant(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "    \n",
    "class PreResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,quant, num_classes=10, depth=20):\n",
    "\n",
    "        super(PreResNet, self).__init__()\n",
    "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
    "        n = (depth - 2) // 6\n",
    "\n",
    "        block = BasicBlock\n",
    "\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.layer1 = self._make_layer(block, 16, n, quant)\n",
    "        self.layer2 = self._make_layer(block, 32, n, quant, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, n, quant, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        self.quant = quant()\n",
    "        IBM_half = FloatingPoint(exp=6, man=9)\n",
    "        self.quant_half = Quantizer(IBM_half, IBM_half, \"nearest\", \"nearest\")\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, quant, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "            )\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.inplanes, planes, quant , stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, quant))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant_half(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.quant(x)\n",
    "\n",
    "        x = self.layer1(x)  # 32x32\n",
    "        x = self.layer2(x)  # 16x16\n",
    "        x = self.layer3(x)  # 8x8\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.quant(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.quant_half(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1628520686455,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "0Q0sOJlxXr7m"
   },
   "outputs": [],
   "source": [
    "# define Three floating point formats\n",
    "bit_8 = FloatingPoint(exp=5, man=2)\n",
    "bit_16 = FloatingPoint(exp=6, man=9)\n",
    "bit_32 = FloatingPoint(exp=8, man=23)\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=bit_8, backward_number=bit_8,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1628520687102,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "Df_x9rYgXr7n"
   },
   "outputs": [],
   "source": [
    "model = PreResNet(act_error_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1628520687102,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "x6RYFGnwXr7o",
    "outputId": "4e32796d-e30f-4145-8787-8a1f5690b86f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1106140/477816878.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./PreResNet_fp32.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./PreResNet_fp32.pth')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1628520687103,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "Iw_TioBwXr7o"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' # change device to 'cuda' if you want to run this example on cuda\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1628520687103,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "Rd5cwB5oXr7p"
   },
   "outputs": [],
   "source": [
    "def run_test(loader, model, criterion, optimizer=None):\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3289,
     "status": "ok",
     "timestamp": 1628520690367,
     "user": {
      "displayName": "김민수",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWgSgl9ijMSWAX7wXq6HGE4t1UuYaYdIHX6Jo2CA=s64",
      "userId": "08966804738851346688"
     },
     "user_tz": -540
    },
    "id": "dD1nssfBXr7p",
    "outputId": "b9b2d2a2-9030-48f8-f794-383c5c71cc86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 123.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2672718163609505, 'accuracy': 92.10000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_res = run_test(loaders['test'], model, F.cross_entropy, optimizer=optimizer)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.2. Trans-Precision Inference on LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b136dcf285504d4898812bea539d1d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a6aa2d23924bb792f425a6b20b4ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e7ccea39424c1a95c2e4f6b0d9f09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde711e1786347b6bc89948e8510d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5879c59a43d247878f6cb85be266c79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25c8ac9f6f345089be869e09f6b2f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c787d98b77a2428a949c09c6a7ee965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "LLM = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32,\n",
    "    attn_implementation=\"eager\",\n",
    "    device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me a short introduction of Samsung Electronics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Electronics is one of the world's largest and most successful electronics companies, with a presence in over 190 countries. The company was founded in 1938 by Lee Dong-hwan and has since grown to become one of the world's leading producers of consumer electronics, including smartphones, TVs, computers, and other devices.\n",
      "\n",
      "Samsung Electronics operates several major divisions, including the Mobile Phone Division, which produces smartphones, tablets, and other mobile devices; the TV Division, which produces TVs, LCD monitors, and other home entertainment products; the Consumer Electronics Division, which produces a wide range of consumer electronics products, including televisions\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = LLM.generate(\n",
    "    model_inputs.input_ids,\n",
    "    num_beams=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=128\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Quantized Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.cache_utils import Cache, DynamicCache\n",
    "\n",
    "class MatMul(nn.Module):\n",
    "    def forward(self, A, B):\n",
    "        return A @ B\n",
    "\n",
    "class QuantMatMul(nn.Module):\n",
    "    def __init__(self, qbit):\n",
    "        super().__init__()\n",
    "        self.quantizer = Quantizer(forward_number=qbit, backward_number=qbit,\n",
    "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    def forward(self, A, B):\n",
    "        qA = self.quantizer.quantize(A.data)\n",
    "        qB = self.quantizer.quantize(B.data)\n",
    "        return qA @ qB\n",
    "\n",
    "from transformers.models.qwen2.modeling_qwen2 import rotate_half, apply_rotary_pos_emb, repeat_kv\n",
    "\n",
    "def attn_forward(\n",
    "    self,\n",
    "    hidden_states: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.LongTensor] = None,\n",
    "    past_key_value: Optional[Cache] = None,\n",
    "    output_attentions: bool = False,\n",
    "    use_cache: bool = False,\n",
    "    **kwargs,\n",
    ") -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "    if \"padding_mask\" in kwargs:\n",
    "        warnings.warn(\n",
    "            \"Passing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\"\n",
    "        )\n",
    "    bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "    query_states = self.q_proj(hidden_states)\n",
    "    key_states = self.k_proj(hidden_states)\n",
    "    value_states = self.v_proj(hidden_states)\n",
    "\n",
    "    query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "    key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "    value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "    kv_seq_len = key_states.shape[-2]\n",
    "    if past_key_value is not None:\n",
    "        if self.layer_idx is None:\n",
    "            raise ValueError(\n",
    "                f\"The cache structure has changed since version v4.36. If you are using {self.__class__.__name__} \"\n",
    "                \"for auto-regressive decoding with k/v caching, please make sure to initialize the attention class \"\n",
    "                \"with a layer index.\"\n",
    "            )\n",
    "        kv_seq_len += past_key_value.get_usable_length(kv_seq_len, self.layer_idx)\n",
    "    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
    "    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n",
    "\n",
    "    if past_key_value is not None:\n",
    "        cache_kwargs = {\"sin\": sin, \"cos\": cos}  # Specific to RoPE models\n",
    "        key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
    "\n",
    "    # repeat k/v heads if n_kv_heads < n_heads\n",
    "    key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "    value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "\n",
    "    attn_weights = self.matmul1(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "    if attn_weights.size() != (bsz, self.num_heads, q_len, kv_seq_len):\n",
    "        raise ValueError(\n",
    "            f\"Attention weights should be of size {(bsz, self.num_heads, q_len, kv_seq_len)}, but is\"\n",
    "            f\" {attn_weights.size()}\"\n",
    "        )\n",
    "\n",
    "    if attention_mask is not None:\n",
    "        if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
    "            raise ValueError(\n",
    "                f\"Attention mask should be of size {(bsz, 1, q_len, kv_seq_len)}, but is {attention_mask.size()}\"\n",
    "            )\n",
    "\n",
    "        attn_weights = attn_weights + attention_mask\n",
    "\n",
    "    # upcast attention to fp32\n",
    "    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "    attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
    "    attn_output = self.matmul2(attn_weights, value_states)\n",
    "\n",
    "    if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
    "        raise ValueError(\n",
    "            f\"`attn_output` should be of size {(bsz, self.num_heads, q_len, self.head_dim)}, but is\"\n",
    "            f\" {attn_output.size()}\"\n",
    "        )\n",
    "\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "    attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
    "\n",
    "    attn_output = self.o_proj(attn_output)\n",
    "\n",
    "    if not output_attentions:\n",
    "        attn_weights = None\n",
    "\n",
    "    return attn_output, attn_weights, past_key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantLinear(nn.Linear):\n",
    "    def __init__(self,in_features,out_features,bias,qbit):\n",
    "        super().__init__(in_features,out_features,bias)\n",
    "        self.quantizer_x = Quantizer(forward_number=qbit, backward_number=qbit,\n",
    "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "        self.quantizer_w = Quantizer(forward_number=qbit, backward_number=qbit,\n",
    "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    def forward(self,x):\n",
    "        w = self.weight.clone()\n",
    "        qx = self.quantizer_x.quantize(x.data)\n",
    "        qw = self.quantizer_w.quantize(w.data)\n",
    "        return F.linear(qx,qw,self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Attention(\n",
       "  (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "  (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "  (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "  (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM.model.layers[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "def get_QLLM(LLM, qbit):\n",
    "    from transformers.models.qwen2.modeling_qwen2 import Qwen2Attention\n",
    "    for name, module in LLM.named_modules():\n",
    "        if isinstance(module, Qwen2Attention):\n",
    "            setattr(module, \"matmul1\", QuantMatMul(qbit))\n",
    "            setattr(module, \"matmul2\", QuantMatMul(qbit))\n",
    "            module.forward = MethodType(attn_forward, module)\n",
    "            \n",
    "    wrapped_modules={}\n",
    "    module_dict={}\n",
    "    it=[(name,m) for name,m in LLM.named_modules()]\n",
    "    for name,m in it:\n",
    "        module_dict[name]=m\n",
    "        idx=name.rfind('.')\n",
    "        if idx==-1:\n",
    "            idx=0\n",
    "        father_name=name[:idx]\n",
    "        if father_name in module_dict:\n",
    "            father_module=module_dict[father_name]\n",
    "        else:\n",
    "            raise RuntimeError(f\"father module {father_name} not found\")\n",
    "        if isinstance(m,nn.Linear) and 'head' not in name:\n",
    "            idx = idx+1 if idx != 0 else idx\n",
    "            new_m = QuantLinear(m.in_features,m.out_features,m.bias is not None,qbit=qbit)\n",
    "            new_m.weight.data=m.weight.data\n",
    "            new_m.bias=m.bias\n",
    "            replace_m=new_m\n",
    "            wrapped_modules[name] = new_m\n",
    "            setattr(father_module,name[idx:],replace_m)\n",
    "    LLM.eval()\n",
    "    return wrapped_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbit = FloatingPoint(exp=5, man=2)\n",
    "wrapped_modules = get_QLLM(LLM, qbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): QuantLinear(\n",
       "            in_features=896, out_features=896, bias=True\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (k_proj): QuantLinear(\n",
       "            in_features=896, out_features=128, bias=True\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (v_proj): QuantLinear(\n",
       "            in_features=896, out_features=128, bias=True\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (o_proj): QuantLinear(\n",
       "            in_features=896, out_features=896, bias=False\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          (matmul1): QuantMatMul(\n",
       "            (quantizer): Quantizer()\n",
       "          )\n",
       "          (matmul2): QuantMatMul(\n",
       "            (quantizer): Quantizer()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): QuantLinear(\n",
       "            in_features=896, out_features=4864, bias=False\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (up_proj): QuantLinear(\n",
       "            in_features=896, out_features=4864, bias=False\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (down_proj): QuantLinear(\n",
       "            in_features=4864, out_features=896, bias=False\n",
       "            (quantizer_x): Quantizer()\n",
       "            (quantizer_w): Quantizer()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Attention(\n",
       "  (q_proj): QuantLinear(\n",
       "    in_features=896, out_features=896, bias=True\n",
       "    (quantizer_x): Quantizer()\n",
       "    (quantizer_w): Quantizer()\n",
       "  )\n",
       "  (k_proj): QuantLinear(\n",
       "    in_features=896, out_features=128, bias=True\n",
       "    (quantizer_x): Quantizer()\n",
       "    (quantizer_w): Quantizer()\n",
       "  )\n",
       "  (v_proj): QuantLinear(\n",
       "    in_features=896, out_features=128, bias=True\n",
       "    (quantizer_x): Quantizer()\n",
       "    (quantizer_w): Quantizer()\n",
       "  )\n",
       "  (o_proj): QuantLinear(\n",
       "    in_features=896, out_features=896, bias=False\n",
       "    (quantizer_x): Quantizer()\n",
       "    (quantizer_w): Quantizer()\n",
       "  )\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  (matmul1): QuantMatMul(\n",
       "    (quantizer): Quantizer()\n",
       "  )\n",
       "  (matmul2): QuantMatMul(\n",
       "    (quantizer): Quantizer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM.model.layers[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me a short introduction of Samsung Electronics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/devrok/.conda/envs/qpt/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Electronics is a South Korean multinational corporation headquartered in Seoul, South Korea. It was founded on September 25, 1968 by Lee Dong-gun and his brother-in-law Lee Dong-hun. The company's main business is the production and sale of electronic devices such as smartphones, tablets, TVs, and other consumer electronics.\n",
      "\n",
      "Samsung Electronics has been one of the leading companies in the global electronics industry for many years. It has a strong presence in various regions around the world including Asia, Europe, North America, and Africa. \n",
      "\n",
      "The company operates through its subsidiaries like Samsung Electronics Co., Ltd., Samsung Display Co., Ltd\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = LLM.generate(\n",
    "    model_inputs.input_ids,\n",
    "    num_beams=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=128\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MXformat ---> 대체 가능한 모듈"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "qtorch_tutorial.ipynb",
   "provenance": [
    {
     "file_id": "1-YGxpZS47ZiJPP3duAe8XIwygy3JsfYF",
     "timestamp": 1628302354375
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
